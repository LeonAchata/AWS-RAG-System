# Sistema RAG (Retrieval-Augmented Generation) con AWS

[![AWS](https://img.shields.io/badge/AWS-Bedrock-orange)](https://aws.amazon.com/bedrock/)
[![CDK](https://img.shields.io/badge/AWS-CDK-blue)](https://aws.amazon.com/cdk/)
[![Python](https://img.shields.io/badge/Python-3.11-green)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow)](LICENSE)

## ğŸš€ Quick Start

```powershell
# 1. Clonar el repositorio
git clone https://github.com/LeonAchata/AWS-RAG-System.git
cd AWS-RAG-System

# 2. Instalar CDK globalmente (si no lo tienes)
npm install -g aws-cdk

# 3. Configurar AWS credentials
aws configure

# 4. Deploy con un comando
cd scripts
.\deploy.ps1 all
```

**[Ver guÃ­a completa de inicio rÃ¡pido â†’](docs/QUICK_START.md)**

## ğŸ“– DescripciÃ³n General del Proyecto

Este proyecto implementa un **sistema completo de RAG (Retrieval-Augmented Generation)** utilizando servicios de AWS, especÃ­ficamente **Amazon Bedrock** para embeddings y generaciÃ³n de respuestas con Claude 3. 

El sistema permite:
- âœ… Cargar documentos (PDF, DOCX, TXT, HTML, MD)
- âœ… Procesamiento automÃ¡tico con chunking inteligente
- âœ… IndexaciÃ³n en base de datos vectorial (OpenSearch)
- âœ… Consultas en lenguaje natural
- âœ… Respuestas contextualizadas con fuentes

**Todo deployado automÃ¡ticamente con AWS CDK.**

## Arquitectura del Sistema

El sistema estÃ¡ dividido en dos flujos principales:

### 1. Flujo de Ingesta (Ingestion Pipeline)

Este flujo se encarga de procesar y almacenar documentos en el sistema:

**Componentes:**
- **Fuentes de Datos**: El sistema acepta documentos de mÃºltiples fuentes (S3, bases de datos relacionales, archivos locales)
- **Lambda de Ingesta**: FunciÃ³n serverless que orquesta el proceso de carga
- **S3 Raw**: Bucket de almacenamiento para documentos originales
- **Procesamiento y Chunking**: Divide los documentos en fragmentos manejables
- **Bedrock Titan Embeddings**: Genera vectores de embedding para cada fragmento de texto
- **Almacenamiento de Ãndices**: Guarda los vectores en una base de datos vectorial
- **Vector Database**: Almacena y permite bÃºsqueda eficiente de vectores (OpenSearch, DynamoDB con extensiones vectoriales, o Aurora)

### 2. Flujo de Consulta (Query Pipeline)

Este flujo gestiona las peticiones de los usuarios y genera respuestas:

**Componentes:**
- **User Application**: Interfaz de usuario (web, mÃ³vil, o CLI)
- **API Gateway**: Punto de entrada para las peticiones HTTP
- **Lambda de Query**: Procesa las consultas de los usuarios
- **Bedrock Titan Embeddings**: Convierte la consulta del usuario en un vector
- **Vector Database**: Recupera los documentos mÃ¡s relevantes mediante bÃºsqueda de similitud
- **Bedrock LLM (Claude/OpenAI)**: Genera respuestas contextuales basadas en los documentos recuperados
- **Respuesta al Usuario**: Retorna la respuesta generada a travÃ©s de API Gateway

## Stack TecnolÃ³gico Recomendado

### Servicios de AWS Core

1. **Amazon S3**
   - Almacenamiento de documentos originales
   - Bucket para datos raw
   - Bucket para logs y metadatos
   - Versionado habilitado para trazabilidad

2. **AWS Lambda**
   - Lambda de Ingesta: Procesa documentos entrantes
   - Lambda de Query: Maneja peticiones de bÃºsqueda
   - Runtime: Python 3.11 o superior
   - Memoria recomendada: 1024-2048 MB segÃºn tamaÃ±o de documentos

3. **Amazon API Gateway**
   - REST API o HTTP API
   - AutenticaciÃ³n mediante IAM, Cognito, o API Keys
   - Throttling y rate limiting configurado

4. **Amazon Bedrock**
   - Modelo de Embeddings: Titan Embeddings V2
   - Modelo LLM: Claude 3 Sonnet o Claude 3.5 Sonnet
   - ConfiguraciÃ³n de temperatura y tokens mÃ¡ximos

### Base de Datos Vectorial (Opciones)

**OpciÃ³n 1: Amazon OpenSearch Service**
- Motor de bÃºsqueda especializado con soporte nativo para vectores
- Plugin k-NN para bÃºsqueda de vecinos mÃ¡s cercanos
- Escalabilidad horizontal
- VisualizaciÃ³n con OpenSearch Dashboards

**OpciÃ³n 2: Amazon DynamoDB con extensiones**
- SoluciÃ³n serverless completamente gestionada
- Menor costo para volÃºmenes pequeÃ±os/medianos
- Requiere implementaciÃ³n personalizada de bÃºsqueda vectorial

**OpciÃ³n 3: Amazon Aurora PostgreSQL con pgvector**
- Extension pgvector para bÃºsqueda vectorial
- Ventaja si ya se usa PostgreSQL
- Consultas SQL tradicionales combinadas con bÃºsqueda vectorial

### Procesamiento de Documentos

**LibrerÃ­as de Parsing:**
- **LangChain**: Framework completo para aplicaciones LLM
- **PyPDF2/pdfplumber**: ExtracciÃ³n de texto de PDFs
- **python-docx**: Procesamiento de documentos Word
- **Beautiful Soup**: Parsing de HTML
- **Unstructured**: Biblioteca universal para mÃºltiples formatos

**Text Splitting:**
- RecursiveCharacterTextSplitter de LangChain
- TamaÃ±o de chunk recomendado: 500-1000 tokens
- Overlap entre chunks: 50-100 tokens

### Infraestructura como CÃ³digo

**Opciones:**
- **AWS CDK (Cloud Development Kit)**: Python o TypeScript
- **Terraform**: Para equipos multi-cloud
- **AWS SAM (Serverless Application Model)**: EspecÃ­fico para arquitecturas serverless
- **CloudFormation**: Nativo de AWS pero mÃ¡s verboso

### Frontend (Opcional)

**Para AplicaciÃ³n Web:**
- **React** + **Vite**: SPA moderna y rÃ¡pida
- **Next.js**: Si se requiere SSR
- **Tailwind CSS**: EstilizaciÃ³n
- **Axios/Fetch**: Cliente HTTP

**Para CLI:**
- **Click** o **Typer**: Frameworks de CLI en Python
- **Rich**: Formato y visualizaciÃ³n en terminal

## ğŸ“ Estructura del Proyecto

```
AWS-RAG-System/
â”œâ”€â”€ infrastructure/          # ğŸ—ï¸ AWS CDK - Infraestructura como cÃ³digo
â”‚   â”œâ”€â”€ stacks/
â”‚   â”‚   â””â”€â”€ rag_stack.py    # Stack principal con todos los recursos
â”‚   â”œâ”€â”€ constructs/         # Componentes reutilizables de CDK
â”‚   â”œâ”€â”€ config/             # Configuraciones por ambiente (dev/staging/prod)
â”‚   â”œâ”€â”€ app.py              # Punto de entrada CDK
â”‚   â””â”€â”€ cdk.json            # ConfiguraciÃ³n CDK
â”‚
â”œâ”€â”€ lambda/                  # ğŸ”§ Funciones Lambda
â”‚   â”œâ”€â”€ ingestion/          # Lambda de ingesta de documentos
â”‚   â”‚   â”œâ”€â”€ handler.py      # âœ… Implementado
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ utils/
â”‚   â”‚       â”œâ”€â”€ document_processor.py  # Soporte PDF, DOCX, TXT, HTML
â”‚   â”‚       â””â”€â”€ text_chunker.py        # Chunking inteligente con LangChain
â”‚   â””â”€â”€ query/              # Lambda de consultas
â”‚       â”œâ”€â”€ handler.py      # âœ… Implementado
â”‚       â”œâ”€â”€ requirements.txt
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ prompt_builder.py      # ConstrucciÃ³n de prompts RAG
â”‚           â””â”€â”€ cache.py               # Sistema de cachÃ©
â”‚
â”œâ”€â”€ shared/                  # ğŸ“¦ CÃ³digo compartido
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ document.py     # Modelos de datos (Document, Chunk, Query)
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ bedrock_client.py      # Cliente para Bedrock (embeddings + LLM)
â”‚   â”‚   â””â”€â”€ opensearch_client.py   # Cliente para OpenSearch (indexaciÃ³n + bÃºsqueda)
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ settings.py     # ConfiguraciÃ³n centralizada
â”‚
â”œâ”€â”€ scripts/                 # ğŸš€ Scripts de deployment y testing
â”‚   â”œâ”€â”€ deploy.py           # Script Python de deployment
â”‚   â”œâ”€â”€ deploy.ps1          # Script PowerShell de deployment
â”‚   â””â”€â”€ test_system.py      # Tests automÃ¡ticos del sistema
â”‚
â”œâ”€â”€ docs/                    # ğŸ“š DocumentaciÃ³n
â”‚   â”œâ”€â”€ QUICK_START.md      # GuÃ­a de inicio rÃ¡pido
â”‚   â””â”€â”€ SETUP.md            # Setup detallado
â”‚
â”œâ”€â”€ tests/                   # ğŸ§ª Tests (por implementar)
â”‚   â”œâ”€â”€ unit/
â”‚   â””â”€â”€ integration/
â”‚
â””â”€â”€ README.md               # Este archivo
```

**Estado actual:** âœ… Lambdas implementadas | âœ… CDK configurado | â­ï¸ Listo para deploy

## ğŸ¯ CaracterÃ­sticas Implementadas

### Lambda de Ingesta âœ…
- **Procesamiento Multi-formato:** PDF, DOCX, TXT, HTML, Markdown
- **Chunking Inteligente:** DivisiÃ³n automÃ¡tica con LangChain (800 chars, 100 overlap)
- **Embeddings con Bedrock:** Titan Embeddings V2 (1024 dimensiones)
- **IndexaciÃ³n AutomÃ¡tica:** OpenSearch con k-NN vectorial
- **Triggers S3:** Procesamiento automÃ¡tico al subir documentos
- **ExtracciÃ³n de Metadatos:** TÃ­tulo, autor, fecha, etc.

### Lambda de Query âœ…
- **BÃºsqueda Vectorial:** k-NN con similitud coseno en OpenSearch
- **GeneraciÃ³n con Claude 3:** Respuestas contextualizadas con LLM
- **Sistema de CachÃ©:** Reduce costos y latencia (30 min TTL)
- **Modo Conversacional:** Soporte para historial de chat
- **MÃ©tricas de Confianza:** High/Medium/Low basado en similitud
- **Trazabilidad:** Referencias a documentos fuente con scores
- **Filtros Opcionales:** Por metadatos (tipo, autor, fecha)

### Infraestructura CDK âœ…
- **S3 Buckets:** Raw + Processed con versionado y lifecycle
- **OpenSearch Domain:** k-NN habilitado, cifrado, fine-grained access
- **Lambda Functions:** Con permisos IAM automÃ¡ticos
- **API Gateway:** REST API con CORS y throttling
- **Lambda Layers:** CÃ³digo compartido reutilizable
- **CloudWatch:** Logs y mÃ©tricas automÃ¡ticos
- **Multi-ambiente:** Configs para dev/staging/prod

### Clientes Compartidos âœ…
- **BedrockClient:** Embeddings + LLM con singleton pattern
- **OpenSearchClient:** IndexaciÃ³n + bÃºsqueda vectorial optimizada
- **Modelos de Datos:** Document, Chunk, QueryResult con tipos
- **ConfiguraciÃ³n:** Settings centralizados y parametrizables

### Proceso de Ingesta

1. **Carga de Documento**: Usuario sube documento a travÃ©s de aplicaciÃ³n o directamente a S3
2. **Trigger**: Evento S3 activa Lambda de Ingesta
3. **ExtracciÃ³n**: Lambda extrae texto segÃºn el tipo de documento
4. **Chunking**: Divide el documento en fragmentos con overlap
5. **Metadatos**: Extrae y almacena metadatos (tÃ­tulo, autor, fecha, etc.)
6. **Embedding**: Cada chunk se envÃ­a a Bedrock Titan Embeddings para generar vectores
7. **IndexaciÃ³n**: Vectores y metadatos se almacenan en la base de datos vectorial
8. **ConfirmaciÃ³n**: Sistema registra el documento como procesado

### Proceso de Query

1. **Solicitud del Usuario**: Usuario envÃ­a pregunta a travÃ©s de la aplicaciÃ³n
2. **API Gateway**: Recibe y valida la peticiÃ³n
3. **Lambda Query**: Procesa la consulta
4. **Embedding de Query**: Convierte la pregunta en vector usando Bedrock
5. **BÃºsqueda Vectorial**: Encuentra los top-K documentos mÃ¡s similares en la base de datos
6. **ConstrucciÃ³n de Contexto**: Recupera el texto de los chunks relevantes
7. **Prompt Engineering**: Construye prompt con contexto y pregunta para el LLM
8. **GeneraciÃ³n**: Bedrock Claude genera respuesta basada en el contexto
9. **Respuesta**: Sistema retorna respuesta al usuario con referencias opcionales

## Consideraciones TÃ©cnicas Importantes

### Seguridad

- **IAM Roles**: Principio de mÃ­nimo privilegio para cada componente
- **Encryption**: Datos en reposo (S3, bases de datos) y en trÃ¡nsito (TLS)
- **VPC**: Opcionalmente colocar bases de datos en VPC privada
- **API Security**: AutenticaciÃ³n y autorizaciÃ³n en API Gateway
- **Secrets Manager**: Almacenar credenciales y API keys

### Escalabilidad

- **Lambda Concurrency**: Configurar lÃ­mites de concurrencia reservada
- **DynamoDB**: Configurar auto-scaling o modo on-demand
- **OpenSearch**: Dimensionar cluster segÃºn volumen de datos
- **S3**: Ilimitado, pero considerar polÃ­ticas de lifecycle
- **API Gateway**: Rate limiting por usuario/API key

### Costos

**Factores principales de costo:**
- Invocaciones de Bedrock (embeddings y LLM)
- Almacenamiento en vector database
- Transferencia de datos
- Lambda invocations y compute time
- API Gateway requests

**Optimizaciones:**
- Cachear embeddings de queries frecuentes
- Usar Reserved Capacity si el uso es predecible
- Implementar lifecycle policies en S3
- Monitorear y ajustar tamaÃ±o de chunks

### Monitoreo y Observabilidad

**MÃ©tricas clave:**
- Latencia de ingesta y query
- Tasa de error en Lambdas
- Costos por operaciÃ³n en Bedrock
- TamaÃ±o de Ã­ndice vectorial
- Relevancia de resultados (mÃ©tricas de retrieval)

**Herramientas:**
- **CloudWatch**: Logs y mÃ©tricas nativas
- **X-Ray**: Trazado distribuido
- **CloudWatch Dashboards**: VisualizaciÃ³n de mÃ©tricas
- **Alarmas**: Notificaciones ante anomalÃ­as

### Calidad del RAG

**MÃ©tricas de evaluaciÃ³n:**
- **Precision@K**: Relevancia de los top-K resultados
- **Recall**: Cobertura de documentos relevantes
- **Latencia**: Tiempo de respuesta end-to-end
- **Cosine Similarity**: Similitud entre query y documentos recuperados

**Mejoras:**
- Fine-tuning de tamaÃ±o de chunk y overlap
- Experimentar con diferentes modelos de embedding
- Implementar re-ranking de resultados
- Usar metadatos para filtrado pre-bÃºsqueda
- Implementar feedback loop de usuarios

## Variables de ConfiguraciÃ³n CrÃ­ticas

### Para el Sistema de Embeddings
- DimensiÃ³n de vectores (segÃºn modelo elegido)
- Modelo de embedding (Titan Embeddings V2: 1024 dimensiones)
- NormalizaciÃ³n de vectores

### Para Text Chunking
- TamaÃ±o de chunk (500-1000 tokens recomendado)
- Overlap entre chunks (10-20% del tamaÃ±o)
- Estrategia de splitting (por pÃ¡rrafo, sentencia, carÃ¡cter)

### Para Retrieval
- NÃºmero de documentos a recuperar (K = 3-5 tÃ­picamente)
- MÃ©todo de similitud (cosine, euclidean, dot product)
- Threshold de similitud mÃ­nima

### Para el LLM
- Modelo (Claude 3 Sonnet, Claude 3.5 Sonnet)
- Temperature (0.1-0.3 para respuestas mÃ¡s determinÃ­sticas)
- Max tokens de respuesta (512-2048)
- System prompt para guiar comportamiento

## ğŸš€ Deployment

### Prerequisitos

```powershell
# Verificar instalaciones
node --version    # v18+
aws --version     # AWS CLI
cdk --version     # AWS CDK
python --version  # 3.11+
```

### Deploy AutomÃ¡tico

```powershell
# OpciÃ³n 1: PowerShell (Windows)
cd scripts
.\deploy.ps1 all

# OpciÃ³n 2: Python (multiplataforma)
cd scripts
python deploy.py all
```

### Deploy Manual

```powershell
cd infrastructure

# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Bootstrap (solo primera vez)
cdk bootstrap

# 3. Ver cambios
cdk diff

# 4. Desplegar
cdk deploy
```

**Tiempo:** ~15-20 minutos (OpenSearch tarda en crear)

### Outputs del Stack

DespuÃ©s del deployment:

```
âœ… RagSystemStack

Outputs:
RagSystemStack.ApiUrl = https://xyz.execute-api.us-east-1.amazonaws.com/prod/
RagSystemStack.QueryEndpoint = .../query
RagSystemStack.IngestEndpoint = .../ingest
RagSystemStack.RawBucketName = ragsystemstack-rawdocumentsbucket-xyz
RagSystemStack.OpenSearchEndpoint = search-rag-xyz.us-east-1.es.amazonaws.com
```

**[Ver documentaciÃ³n completa de deployment â†’](infrastructure/README.md)**

## ğŸ§ª Testing

### Test AutomÃ¡tico

```powershell
cd scripts
python test_system.py --api-url YOUR_API_URL --bucket YOUR_BUCKET_NAME
```

### Test Manual

```powershell
# 1. Health check
curl https://YOUR_API_URL/health

# 2. Subir documento
aws s3 cp documento.pdf s3://YOUR_BUCKET/documents/

# 3. Hacer query
curl -X POST https://YOUR_API_URL/query \
  -H "Content-Type: application/json" \
  -d '{"query": "Â¿QuÃ© es machine learning?", "top_k": 5}'
```

## ğŸ’¡ Uso

### Subir Documentos

```powershell
# Via S3 (activa procesamiento automÃ¡tico)
aws s3 cp mi-documento.pdf s3://YOUR_BUCKET/documents/

# Via API (procesamiento directo)
curl -X POST https://YOUR_API_URL/ingest \
  -H "Content-Type: application/json" \
  -d '{"content": "...", "filename": "doc.txt"}'
```

### Realizar Consultas

```powershell
# Query simple
curl -X POST https://YOUR_API_URL/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Â¿CuÃ¡les son las ventajas del deep learning?",
    "top_k": 5,
    "include_sources": true
  }'

# Query con filtros
curl -X POST https://YOUR_API_URL/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Â¿QuÃ© dice sobre seguridad?",
    "filters": {"document_type": "pdf"},
    "min_similarity": 0.75
  }'

# Query conversacional
curl -X POST https://YOUR_API_URL/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Â¿Y cuÃ¡l es la diferencia con IA tradicional?",
    "conversational": true,
    "conversation_history": [...]
  }'
```

### Response Format

```json
{
  "query": "Â¿QuÃ© es machine learning?",
  "answer": "Machine Learning es...",
  "sources": [
    {
      "document_id": "uuid",
      "filename": "ml-guide.pdf",
      "chunks_used": [{"chunk_index": 0, "score": 0.92}]
    }
  ],
  "confidence": {
    "confidence": "high",
    "avg_similarity": 0.87,
    "max_similarity": 0.92
  },
  "response_time": 2.3,
  "from_cache": false
}
```

## ğŸ“Š Monitoreo

### CloudWatch

```powershell
# Ver logs de Ingesta
aws logs tail /aws/lambda/RagSystemStack-IngestionLambda --follow

# Ver logs de Query
aws logs tail /aws/lambda/RagSystemStack-QueryLambda --follow
```

### OpenSearch Dashboard

```
https://YOUR_OPENSEARCH_ENDPOINT/_dashboards
```

### MÃ©tricas Clave

- Invocaciones Lambda
- Errores y timeouts
- Latencia (P50, P95, P99)
- Cache hit rate
- Costos de Bedrock

## ğŸ’° Costos Estimados

### Ambiente Dev

- OpenSearch (t3.small, 1 nodo): ~$25/mes
- Lambda (1M invocaciones): ~$5/mes
- S3 (10 GB): ~$0.23/mes
- API Gateway (1M requests): ~$3.50/mes
- **Bedrock (variable):**
  - Embeddings: $0.0001/1K tokens
  - Claude 3 Sonnet: $0.003/1K input, $0.015/1K output

**Total base: ~$34/mes + Bedrock segÃºn uso**

### Optimizaciones

- âœ… CachÃ© habilitado (reduce 40-60% llamadas a Bedrock)
- âœ… Batch processing de embeddings
- âœ… Lifecycle policies en S3
- âœ… Reserved capacity para OpenSearch (30-70% ahorro)

## ğŸ› ï¸ ConfiguraciÃ³n

### Variables de Entorno (Lambda)

```bash
# Bedrock
BEDROCK_EMBEDDING_MODEL=amazon.titan-embed-text-v2:0
BEDROCK_LLM_MODEL=anthropic.claude-3-sonnet-20240229-v1:0

# OpenSearch
OPENSEARCH_ENDPOINT=search-rag-xyz.us-east-1.es.amazonaws.com
OPENSEARCH_INDEX=rag-documents

# RAG Parameters
CHUNK_SIZE=800
CHUNK_OVERLAP=100
TOP_K=5
MIN_SIMILARITY=0.7
USE_CACHE=true
```

### ConfiguraciÃ³n por Ambiente

Edita `infrastructure/config/stack_config.py`:

```python
# Cambiar ambiente
environment = "dev"    # o "staging", "prod"
```

Diferencias automÃ¡ticas:
- Instancias mÃ¡s grandes en prod
- MÃ¡s nodos OpenSearch
- Timeouts mayores
- Retention policies diferentes

## ğŸ”§ Desarrollo Local

### Setup

```powershell
# Clonar repo
git clone https://github.com/LeonAchata/AWS-RAG-System.git
cd AWS-RAG-System

# Crear entorno virtual
python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate # Linux/Mac

# Instalar dependencias
pip install -r requirements.txt
pip install -r lambda/ingestion/requirements.txt
pip install -r lambda/query/requirements.txt
```

### Testing Local (sin AWS)

```python
# Test de procesamiento de documentos
from lambda.ingestion.utils.document_processor import DocumentProcessor

text = DocumentProcessor.extract_text(pdf_content, ".pdf")
print(text[:500])

# Test de chunking
from lambda.ingestion.utils.text_chunker import chunk_text

chunks = chunk_text(text, chunk_size=800)
print(f"Generados {len(chunks)} chunks")
```

## ğŸ“š DocumentaciÃ³n Adicional

- **[Quick Start Guide](docs/QUICK_START.md)** - Inicio en 5 minutos
- **[CDK Deployment](infrastructure/README.md)** - GuÃ­a completa de infraestructura
- **[Lambda Ingestion](lambda/ingestion/README.md)** - DocumentaciÃ³n del Lambda de ingesta
- **[Lambda Query](lambda/query/README.md)** - DocumentaciÃ³n del Lambda de query
- **[Setup Detallado](docs/SETUP.md)** - ConfiguraciÃ³n paso a paso

## ğŸ¤ Contribuir

```powershell
# 1. Fork el repo
# 2. Crear branch
git checkout -b feature/nueva-funcionalidad

# 3. Hacer cambios y commit
git commit -m "feat: agregar nueva funcionalidad"

# 4. Push
git push origin feature/nueva-funcionalidad

# 5. Crear Pull Request
```

## ğŸ“ License

MIT License - ver [LICENSE](LICENSE) para detalles

## ğŸ™ Agradecimientos

- AWS Bedrock por los modelos de IA
- LangChain por las herramientas de procesamiento
- OpenSearch por la bÃºsqueda vectorial

---

**Desarrollado con â¤ï¸ usando AWS CDK, Python y Bedrock**

### Fase 1: Setup BÃ¡sico
1. Configurar cuenta de AWS y permisos
2. Habilitar Amazon Bedrock y solicitar acceso a modelos
3. Crear buckets S3 bÃ¡sicos
4. Implementar Lambda de ingesta simple (solo un tipo de documento)
5. Configurar base de datos vectorial bÃ¡sica

### Fase 2: Pipeline de Ingesta Completo
1. AÃ±adir soporte para mÃºltiples formatos de documento
2. Implementar chunking inteligente
3. AÃ±adir procesamiento de metadatos
4. Implementar manejo de errores y reintentos
5. Crear sistema de logs estructurados

### Fase 3: Pipeline de Query
1. Implementar Lambda de query
2. Configurar API Gateway
3. Implementar bÃºsqueda vectorial
4. Integrar con Bedrock LLM
5. Optimizar prompt engineering

### Fase 4: Frontend y UX
1. Crear interfaz de usuario bÃ¡sica
2. Implementar carga de documentos
3. Implementar interfaz de chat/bÃºsqueda
4. AÃ±adir visualizaciÃ³n de resultados con referencias

### Fase 5: OptimizaciÃ³n y ProducciÃ³n
1. Implementar cachÃ©
2. AÃ±adir monitoreo completo
3. Optimizar costos
4. Implementar CI/CD
5. DocumentaciÃ³n completa
6. Testing de carga

## Recursos y Referencias

### DocumentaciÃ³n Oficial
- AWS Bedrock Documentation
- Amazon OpenSearch Service Guide
- AWS Lambda Best Practices
- LangChain Documentation

### Conceptos Clave a Estudiar
- Vector embeddings y similitud coseno
- TÃ©cnicas de prompt engineering
- RAG patterns y mejores prÃ¡cticas
- Chunking strategies
- Arquitecturas serverless en AWS

### Herramientas de Desarrollo
- AWS CLI para gestiÃ³n de recursos
- boto3 para Python SDK
- Postman para testing de APIs
- LocalStack para testing local (opcional)

## PrÃ³ximos Pasos

Una vez comprendida esta arquitectura, el siguiente paso serÃ­a:
1. Decidir quÃ© servicios especÃ­ficos usar (principalmente la base de datos vectorial)
2. Elegir el framework de IaC
3. Comenzar con la implementaciÃ³n del pipeline de ingesta
4. Iterar y expandir funcionalidades